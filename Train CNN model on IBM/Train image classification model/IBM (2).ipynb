{"cells": [{"metadata": {"id": "Uo_8uN4qL7-B"}, "cell_type": "markdown", "source": "# ***IMPORT LIBRARIES***"}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 57, "outputs": [{"output_type": "execute_result", "execution_count": 57, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 58, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='nK4KtDgHAyMI9PkCaS6J_L_ERjoB39nSYRduTKKVkGKY',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'realtimecommunication-donotdelete-pr-nlyywsuyz66pqq'\nobject_key = 'conversation engine for deaf and dumb.zip'\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 59, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 60, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\nfile_paths=unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 61, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 62, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 63, "outputs": [{"output_type": "execute_result", "execution_count": 63, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install tensorflow==2.7.1", "execution_count": 64, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: tensorflow==2.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.7.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (3.3.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (3.2.1)\nRequirement already satisfied: wheel<1.0,>=0.32.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.37.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.23.1)\nCollecting keras<2.8,>=2.7.0rc0\n  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 8.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.15.0)\nRequirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.7.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.1.2)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.2.0)\nRequirement already satisfied: gast<0.5.0,>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (4.1.1)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (3.19.1)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.0)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.12.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.42.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.6.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.1.0)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.20.3)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.12.1)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (14.0.6)\nRequirement already satisfied: tensorboard~=2.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.7.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (58.0.4)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (1.6.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (0.4.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (3.3.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (2.26.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (1.23.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (2.0.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.1) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (0.4.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (2022.9.24)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (2.0.4)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.1) (3.2.1)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: Keras 2.2.4\n    Uninstalling Keras-2.2.4:\n      Successfully uninstalled Keras-2.2.4\nSuccessfully installed keras-2.7.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator", "execution_count": 65, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)", "execution_count": 66, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "test_datagen = ImageDataGenerator(rescale=1/255)", "execution_count": 67, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 68, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 69, "outputs": [{"output_type": "execute_result", "execution_count": 69, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Cd4fHCnfm5lC", "outputId": "6ecb2275-0706-4636-9259-a98853a69ab2"}, "cell_type": "code", "source": "x_train = train_datagen.flow_from_directory(\"/home/wsuser/work/Dataset/training_set\", target_size=(64,64),batch_size=100,\n                                            class_mode='categorical', color_mode =\"grayscale\")", "execution_count": 70, "outputs": [{"output_type": "stream", "text": "Found 15750 images belonging to 9 classes.\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "2Ow1BxObnLIR", "outputId": "dc73f50a-e35e-4431-b6b1-eac58d10e840"}, "cell_type": "code", "source": "x_test = test_datagen.flow_from_directory(\"/home/wsuser/work/Dataset/test_set\", target_size=(64,64),batch_size=100,\n                                         class_mode='categorical', color_mode =\"grayscale\")", "execution_count": 71, "outputs": [{"output_type": "stream", "text": "Found 2250 images belonging to 9 classes.\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "yQhffYL7nV9Q", "outputId": "d34f948e-0bc9-4eca-cb58-fe991aa193ab"}, "cell_type": "code", "source": "len(x_train)", "execution_count": 72, "outputs": [{"output_type": "execute_result", "execution_count": 72, "data": {"text/plain": "158"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "gUAQp0TdncAt", "outputId": "787f860f-4a94-45d9-e2fb-a334001c303b"}, "cell_type": "code", "source": "len(x_test)", "execution_count": 73, "outputs": [{"output_type": "execute_result", "execution_count": 73, "data": {"text/plain": "23"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "6hnVxEafnjAQ", "outputId": "8440e039-46cd-45a5-9865-edd28ac1855b"}, "cell_type": "code", "source": "x_train.class_indices", "execution_count": 74, "outputs": [{"output_type": "execute_result", "execution_count": 74, "data": {"text/plain": "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"}, "metadata": {}}]}, {"metadata": {"id": "a7NZ5SQXMZEL"}, "cell_type": "markdown", "source": "## ***MODEL BUILDING***"}, {"metadata": {"id": "7l5g8LRGnqAN"}, "cell_type": "code", "source": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Convolution2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten", "execution_count": 75, "outputs": []}, {"metadata": {"id": "mD17k9U1nuKJ"}, "cell_type": "code", "source": "#Creating the model\nmodel=Sequential()\n#Adding the layers\nmodel.add(Convolution2D(32,(3,3), input_shape=(64,64,1), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\n\n#adding hidden layers\nmodel.add(Dense(400, activation='relu'))\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(100, activation='relu'))\n\n#Adding the output layer\nmodel.add(Dense(9, activation='softmax'))", "execution_count": 76, "outputs": []}, {"metadata": {"id": "h8i0noNHn1fa"}, "cell_type": "code", "source": "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])", "execution_count": 77, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ts7x_pd7n9ys", "outputId": "75b2d946-75e7-450b-e71a-f4c9a8c389bb"}, "cell_type": "code", "source": "model.fit_generator(x_train, steps_per_epoch=30, epochs=10, validation_data=x_test,validation_steps=50)", "execution_count": 78, "outputs": [{"output_type": "stream", "text": "/tmp/wsuser/ipykernel_164/43643550.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(x_train, steps_per_epoch=30, epochs=10, validation_data=x_test,validation_steps=50)\n", "name": "stderr"}, {"output_type": "stream", "text": "Epoch 1/10\n30/30 [==============================] - ETA: 0s - loss: 0.9823 - accuracy: 0.6644WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n30/30 [==============================] - 15s 492ms/step - loss: 0.9823 - accuracy: 0.6644 - val_loss: 0.4462 - val_accuracy: 0.8827\nEpoch 2/10\n30/30 [==============================] - 12s 383ms/step - loss: 0.2524 - accuracy: 0.9223\nEpoch 3/10\n30/30 [==============================] - 12s 390ms/step - loss: 0.1426 - accuracy: 0.9560\nEpoch 4/10\n30/30 [==============================] - 12s 410ms/step - loss: 0.1030 - accuracy: 0.9710\nEpoch 5/10\n30/30 [==============================] - 15s 490ms/step - loss: 0.0759 - accuracy: 0.9803\nEpoch 6/10\n30/30 [==============================] - 12s 397ms/step - loss: 0.0507 - accuracy: 0.9857\nEpoch 7/10\n30/30 [==============================] - 12s 393ms/step - loss: 0.0359 - accuracy: 0.9890\nEpoch 8/10\n30/30 [==============================] - 12s 400ms/step - loss: 0.0301 - accuracy: 0.9922\nEpoch 9/10\n30/30 [==============================] - 12s 399ms/step - loss: 0.0320 - accuracy: 0.9897\nEpoch 10/10\n30/30 [==============================] - 14s 457ms/step - loss: 0.0208 - accuracy: 0.9940\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 78, "data": {"text/plain": "<keras.callbacks.History at 0x7fed77e67190>"}, "metadata": {}}]}, {"metadata": {"id": "g4TNLLz2-e3k"}, "cell_type": "markdown", "source": "# ***Save the Model***"}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 79, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {"id": "MOSlon9TJ3qI"}, "cell_type": "code", "source": "model.save('CNNengine.h5')", "execution_count": 80, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 81, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {"id": "-R0pKpK2MkSk"}, "cell_type": "markdown", "source": "# ***Import The Packages And Load The Saved Model***"}, {"metadata": {"id": "JfUuOgQdJ8im"}, "cell_type": "code", "source": "from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport cv2", "execution_count": 82, "outputs": []}, {"metadata": {"id": "Orx0Yo93KA5m"}, "cell_type": "code", "source": "model = load_model('CNNengine.h5')", "execution_count": 83, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 117}, "id": "iJlWzSo4KIP4", "outputId": "aecace39-63be-452c-fa81-effb59790b6a"}, "cell_type": "code", "source": "img = image.load_img('/home/wsuser/work/Dataset/test_set/A/1.png',target_size = (100,100))\nimg", "execution_count": 84, "outputs": [{"output_type": "execute_result", "execution_count": 84, "data": {"text/plain": "<PIL.Image.Image image mode=RGB size=100x100 at 0x7FED485F5CA0>", "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAACqklEQVR4nO3cMarqQBQG4JMgkjR2QtoQBFt3oa7AJbgClyBxBWYHdml1B2KV0kIXoGBnkQGL3GLeuzyUJ/fomTGZ+3+lhHHu7zkxTjKXCAAAAAAAAAAAAAAAAJrD+/mhi8WCiGaz2fcrvV6PiI7Ho/i06qn180M7nc7dK4fDgYiUUmEYSk6qrvxPT6BJBMIKguD9QRoBlcXAOMFrVVX9dyyPPVqzoLIYEBYDI6w4juM4fnJAWZZlWRJRGIZhGFb/uDsyz/M8z6sH4/H4z7R83/f9xwP0ld2nSJ6z7BiNRkS02WyGwyERrddr/Xq32yWiy+Vi7q3RhiY9tkatTCYTc387ow2XyyURTadTY5ORYe4KBm3I4GBYuh9NjMyoWEMzMMREMzpYWeY4G5b+OpLlbFgmOHvOIgOnLZcrKwgC2YVJl8MSh7AYGGFlWZZlmbmp1B8qi4Fx37Bx9Eqk4Hei+5X1vX77PvfDEoSwGBAWA8JiQFgMCIsBYTEgLAaExeDy4p92u92IqN1uvz+U+2FpIr8Q0YYMjLCKoiiKwtxU6o+xRLPb7YhoMBgYm0zdoQ0Zmvcw22twgreNHZbzz28/8UpleZ73OyNDGzK8HtYvLK63KitJkiRJpKZSf2hDBplWqv/Fl8hJQ+aOtN7JKnUvU5ZSSmootCGDTGXpT6/O9SUClcUgGZZSSil1Op0Ex6wVIxeW/X6fiPb7vYnBufDIkXO22+2nNtJp4k8rm/19d7fZ1DL97YzrLHetViu0IYPe/2pi89ET2I7ySVYX8CqLixPX6/Xxf1i9yWpl2Vxcnc/n4mOiDRlsr6Nb60Tskf4wZ8OKokh8TGfDMgFhMdgOK03TNE0tv6kUVBYDwmJwNiwTtwJsX5S2Wi36+2y6UVEUnc9n2TGdrSwTvgDz3Vmc0Ls0CgAAAABJRU5ErkJggg==\n"}, "metadata": {}}]}, {"metadata": {"id": "5y0zO7NrMQVM"}, "cell_type": "markdown", "source": "# ***Load The Test Image, Pre-Process It And Predict***"}, {"metadata": {"id": "BaW9_9gOMd9l"}, "cell_type": "code", "source": "from skimage.transform import resize\ndef detect(frame):\n    img=image.img_to_array(frame)\n    img = resize(img,(64,64,1))\n    img = np.expand_dims(img,axis=0)\n    pred=np.argmax(model.predict(img))\n    op=['A','B','C','D','E','F','G','H','I']\n    print(\"THE PREDICTED LETTER IS \",op[pred])", "execution_count": 85, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "IkyDwAyCMms2", "outputId": "b76a5690-189e-4766-ca58-174f5edbae27"}, "cell_type": "code", "source": "img=image.load_img(\"/home/wsuser/work/Dataset/test_set/A/1.png\")\ndetect(img)", "execution_count": 86, "outputs": [{"output_type": "stream", "text": "THE PREDICTED LETTER IS  A\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "k1LlgEmLMqyT", "outputId": "71633ad1-4785-44e9-e5c8-5244b0dc5e25"}, "cell_type": "code", "source": "img = image.load_img('/home/wsuser/work/Dataset/test_set/I/109.png')\npred=detect(img)", "execution_count": 87, "outputs": [{"output_type": "stream", "text": "THE PREDICTED LETTER IS  I\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# IBM Deployment"}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf trainedModel.tgz CNNengine.h5", "execution_count": 88, "outputs": [{"output_type": "stream", "text": "CNNengine.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow as tf\ntf.__version__", "execution_count": 89, "outputs": [{"output_type": "execute_result", "execution_count": 89, "data": {"text/plain": "'2.7.2'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install keras==2.2.4", "execution_count": 90, "outputs": [{"output_type": "stream", "text": "Collecting keras==2.2.4\n  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.20.3)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (5.4.1)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (3.2.1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.15.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.7.3)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.0.8)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.1.2)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.7.0\n    Uninstalling keras-2.7.0:\n      Successfully uninstalled keras-2.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.7.1 requires keras<2.8,>=2.7.0rc0, but you have keras 2.2.4 which is incompatible.\u001b[0m\nSuccessfully installed keras-2.2.4\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client", "execution_count": 91, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.391)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials={\n    \"url\":\"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\":\"e2ka0MNDZZs-Y2_3hvue8au0bmWfwOZtqRJh8mEqiEp5\"\n}\nclient=APIClient(wml_credentials)", "execution_count": 92, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client", "execution_count": 93, "outputs": [{"output_type": "execute_result", "execution_count": 93, "data": {"text/plain": "<ibm_watson_machine_learning.client.APIClient at 0x7fed485796a0>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "def guid_from_space_name(client, specially_abled):\n    space = client.spaces.get_details()\n    return (next(item for item in space['resources'] if item['entity'][\"name\"] == specially_abled)['metadata']['id'])", "execution_count": 95, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid = guid_from_space_name(client, 'specially_abled')\nprint(\"Space UID : \", space_uid)", "execution_count": 96, "outputs": [{"output_type": "stream", "text": "Space UID :  39fb543f-0587-4283-8979-a4987fb5f904\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 97, "outputs": [{"output_type": "execute_result", "execution_count": 97, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 98, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9')", "execution_count": 99, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "software_space_uid", "execution_count": 100, "outputs": [{"output_type": "execute_result", "execution_count": 100, "data": {"text/plain": "'acd9c798-6974-5d2f-a657-ce06e986df4d'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details = client.repository.store_model(model='trainedModel.tgz', meta_props={\n    client.repository.ModelMetaNames.NAME: \"CNNengine.h5\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid,\n    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\"})\nmodel_id = client.repository.get_model_id(model_details)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_id=client.repository.get_model_id(model_details)", "execution_count": 114, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": 115, "outputs": [{"output_type": "execute_result", "execution_count": 115, "data": {"text/plain": "'dd161c21-858d-464f-9dbd-51118f73670c'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,'IBM.tar.gb')", "execution_count": 116, "outputs": [{"output_type": "stream", "text": "Successfully saved model content to file: 'IBM.tar.gb'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 116, "data": {"text/plain": "'/home/wsuser/work/IBM.tar.gb'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 117, "outputs": [{"output_type": "execute_result", "execution_count": 117, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 118, "outputs": [{"output_type": "stream", "text": "CNNengine.h5  \u001b[0m\u001b[01;34mDataset\u001b[0m/  IBM.tar.gb  trainedModel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}